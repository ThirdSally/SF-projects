Задача проекта - собрать датасет и обучить на нем модель, предсказывающую стоимость подержанных автомобилей в городе Москва

Проект состоит из трех ноутбуков:
1. Разбор тестовой выборки
2. Чистка тренировочного датасета
3. Обучение модели


Основной сложностью на проекте для меня стал Scrapy. С прошлого проекта остались сомнения, что BeautifulSoup дастся мне, поэтому я решила изучить другой инструмент.
На то, чтобы разобраться, спарсить часть, отменять, снова писать код и снова ждать у меня ушло 4 дня. Качался датасет дополнительных часов 20.
При этом вышел он небольшим, я не стала скачивать данные по всей России.

Код scrapy в отдельной папке spiders

В целом, результатом (не на лидерборде) я осталась довольна. На этот раз хорошо проработала генерацию новых признаков. К моему удивлению, удаляя один из двух сильно коррелирующих признаков сильно ухудшал метрику
Так же выбросы тоже показались больше полезными для метрики, но я решила их удалить, так как распределение с их удалением становилось все же лучше.

Ознакомилась также с RandomizedSearchCV. Действительно в разы быстрее GridSearchCV, и при этом достаточно хорошо подбирает гиперпараметры.  

Считаю, нужно также практиковаться со стекингом и кросс-валидацией, для улучшения результатов
